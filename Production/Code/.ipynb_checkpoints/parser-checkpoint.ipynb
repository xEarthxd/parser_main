{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parsers(object):\n",
    "    def __init__(self):\n",
    "        import os\n",
    "        import logging\n",
    "        from pymongo import MongoClient\n",
    "        \n",
    "        self.DB_NAME_INIT = 'test2'\n",
    "        self.COLLECTION_NAME_INIT = 'test2'\n",
    "        self.cnx_INIT = MongoClient(\"mongodb://tdri:stafftdri@3.0.20.249:27017\")\n",
    "        self.parsed_false = self.cnx_INIT[self.DB_NAME_INIT][self.COLLECTION_NAME_INIT].find_one({'parsed' : False})\n",
    "        self.file_to_parse = self.parsed_false['file_name']\n",
    "        \n",
    "        logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                    filename='app.log',\n",
    "                    filemode='a')\n",
    "        logging.getLogger('chardet.charsetprober').setLevel(logging.INFO)\n",
    "        self.logger = logging.getLogger(\"Parser Logger\")\n",
    "        self.init_file_name = 'need_to_parse' + '/' + self.file_to_parse.split('.')[0]\n",
    "        self.main_file_name = self.file_to_parse\n",
    "        print(True)\n",
    "    \n",
    "    def get_file_name(self):\n",
    "        return self.main_file_name\n",
    "    \n",
    "    class ParserNotFoundError(Exception):\n",
    "        pass\n",
    "    \n",
    "    class FilenameSplitError(Exception):\n",
    "        pass\n",
    "    \n",
    "    class NotADirectoryError(Exception):\n",
    "        pass\n",
    "    \n",
    "    def find_parser(self, file_name):\n",
    "        \n",
    "        from parsers.jobant_parser import jobant_parser\n",
    "        from parsers.jobbkk_parser import jobbkk_parser\n",
    "        from parsers.jobsawasdee_parser import jobsawasdee_parser\n",
    "        from parsers.jobsdb_parser import jobsdb_parser\n",
    "        from parsers.jobsugoi_parser import jobsugoi_parser\n",
    "        from parsers.jobth_parser import jobth_parser\n",
    "        from parsers.jobthai_parser import jobthai_parser\n",
    "        from parsers.jobthaiweb_parser import jobthaiweb_parser\n",
    "        from parsers.jobtopgun_parser import jobtopgun_parser\n",
    "        from parsers.nationejobs_parser import nationejobs_parser\n",
    "        from parsers.nationejob_parser import nationejob_parser\n",
    "        from parsers.thaibestjobs_parser import thaibestjobs_parser\n",
    "        from parsers.workventure_parser import workventure_parser\n",
    "        from parsers.jobpub_parser import jobpub_parser   \n",
    "        \n",
    "        try: \n",
    "            parser_name = file_name.split(\"/\")[-2]  #  website name indicated via folder name\n",
    "        except:\n",
    "            raise FilenameSplitError\n",
    "    \n",
    "        if(parser_name == \"jobant\"):\n",
    "            return jobant_parser\n",
    "        elif(parser_name == \"jobbkk\"):\n",
    "            return jobbkk_parser\n",
    "        elif(parser_name == \"jobsawasdee\"):\n",
    "            return jobsawasdee_parser\n",
    "        elif(parser_name == \"jobsdb\"):\n",
    "            return jobsdb_parser\n",
    "        elif(parser_name == \"jobsugoi\"):\n",
    "            return jobsugoi_parser\n",
    "        elif(parser_name == \"jobth\"):\n",
    "            return jobth_parser\n",
    "        elif(parser_name == \"jobthai\"):\n",
    "            return jobthai_parser\n",
    "        elif(parser_name == \"jobthaiweb\"):\n",
    "            return jobthaiweb_parser\n",
    "        elif(parser_name == \"jobtopgun\"):\n",
    "            return jobtopgun_parser\n",
    "        elif(parser_name == \"nationejob\"):\n",
    "            return nationejob_parser\n",
    "        elif(parser_name == \"nationejobs\"):\n",
    "            return nationejobs_parser\n",
    "        elif(parser_name == \"thaibestjobs\"):\n",
    "            return thaibestjobs_parser\n",
    "        elif(parser_name == \"workventure\"):\n",
    "            return workventure_parser\n",
    "        elif(parser_name == \"jobpub\"):\n",
    "            return jobpub_parser\n",
    "        \n",
    "    #  Queue_Manager : One queue manager process will recursive read files into queue\n",
    "    \n",
    "    #  Job_worker : Each process will parse the document, then insert into database\n",
    "    def process_job(self, queue, test=False):\n",
    "        import hashlib\n",
    "#         from MongodbSearcher import MongodbSearcher\n",
    "#         from ProvinceMiner.miner_script import ProvinceMiner\n",
    "#         pm = ProvinceMiner()\n",
    "#         ms = MongodbSearcher(\"mongodb://tdri:stafftdri@localhost:27017\", \n",
    "#                      'Company_Search_Index', \n",
    "#                      'company_search_index')\n",
    "        while(True):\n",
    "\n",
    "            job = queue.get()\n",
    "            self.logger.info(\"[Worker] Parsing filename ({})\".format(job))\n",
    "            parser = self.find_parser(job)  #  find the parser for that filename\n",
    "\n",
    "            try:\n",
    "                parsed_data = parser(job)  #  parse using filename\n",
    "                hash_company = hashlib.md5(parsed_data['company'].encode()).hexdigest()\n",
    "                hash_title_th = hashlib.md5(parsed_data['title_th'].encode()).hexdigest()\n",
    "                hash_description = hashlib.md5(parsed_data['description'].encode()).hexdigest()\n",
    "                parsed_data['hash'] = hash_company + hash_title_th + hash_description\n",
    "#                 industry_id = ms.search_industry_id(parsed_data['company'])\n",
    "#                 if(industry_id is not None):\n",
    "#                     parsed_data['industry_id'] = industry_id\n",
    "#                 else:\n",
    "#                     parsed_data['industry_id'] = 'undefined'\n",
    "                \n",
    "#                 province = pm.mine_province(parsed_data)\n",
    "#                 if(province is not None):\n",
    "#                     parsed_data['province'] = province\n",
    "#                 else:\n",
    "#                     parsed_data['province'] = 'undefined'\n",
    "                \n",
    "            except:\n",
    "                self.logger.warning(\"[Worker] Filename ({}) gives error\".format(job))\n",
    "            else:\n",
    "                self.logger.info(\"[Worker] Inserting filename ({})\".format(job))\n",
    "                self.insert_into_db(parsed_data, job)\n",
    " \n",
    "    def insert_into_db(self, parsed_data, job):\n",
    "        from pymongo import MongoClient\n",
    "        import pymongo\n",
    "        DB_NAME = 'test3'\n",
    "        COLLECTION_NAME = 'test3'\n",
    "        cnx = MongoClient(\"mongodb://tdri:stafftdri@3.0.20.249:27017\")\n",
    "        try:\n",
    "            cnx[DB_NAME][COLLECTION_NAME].insert_one(parsed_data)\n",
    "            self.logger.info(\"[Inserted file ({}) is done]\".format(job))\n",
    "            self.cnx_INIT[self.DB_NAME_INIT][self.COLLECTION_NAME_INIT].update_one({'parsed' : False}, {'$set' : {'parsed' : True}})\n",
    "        except:\n",
    "            self.logger.warning(\"[Worker] Found duplicated file filename ({})\".format(job))\n",
    "    \n",
    "\n",
    "    \n",
    "    def queue_manager_job(self, starting, queue):\n",
    "        import os\n",
    "        def list_all_files_into_queue(path_to_folder, queue):\n",
    "            this_folder = os.listdir(path_to_folder)\n",
    "            for file in this_folder:\n",
    "                try: #  This is a folder, recursive case\n",
    "                    sub_files = list_all_files_into_queue(path_to_folder + \"/\" + file, queue)\n",
    "                except NotADirectoryError: #  This is a file (base case)\n",
    "                    queue.put(path_to_folder + \"/\" + file)  #  put full path into queue\n",
    "        self.logger.info(\"[QueueManager] Starting Queue Manager at folder ./{}/\".format(starting))\n",
    "        list_all_files_into_queue(starting, queue)\n",
    "        self.logger.info(\"All jobs are inserted into queue\")\n",
    "\n",
    "        \n",
    "    #  main function : run this cell to start parsing\n",
    "    def main(self, num_process = 4):\n",
    "        \n",
    "        from multiprocessing import Queue, Process\n",
    "        from pymongo import MongoClient\n",
    "        from pymongo.errors import DuplicateKeyError\n",
    "\n",
    "        #  Start queue manager\n",
    "        queue = Queue(maxsize=10000)\n",
    "        queueManager = Process(target=self.queue_manager_job, args=(self.init_file_name, queue))\n",
    "        queueManager.start()\n",
    "\n",
    "        #  Distribute jobs to workers\n",
    "        processes = [Process(target=self.process_job, args=(queue, )) for i in range(num_process)]\n",
    "        for process in processes:\n",
    "            process.start()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
